{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "BDA2021Fall_HW5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaivoKasepuu/BDA_Tartu_MTAT_03_319/blob/master/BDA2021Fall_HW5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peLGGRdTeci0"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\"><b></b>\n",
        "<h1><center> <font color='black'> Homework 05  </font></center></h1>\n",
        "<h2><center> <font color='black'> Customer lifecycle management: Attrition Prediction - Classification </font></center></h2>   \n",
        "<h2><center> <font color='black'> MTAT.03.319 - Business Data Analytics</font></center></h2>\n",
        "<h2><center> <font color='black'> University of Tartu - Fall 2021</font></center></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEIS8WGK0dfw"
      },
      "source": [
        "# Homework instructions\n",
        "- Please name your homeworks in the following format **BDAFall2021_HWX_Name_Surname.ipynb** then it will be easier to grade your homeworks and smaller possibility for a human mistake.\n",
        "- Please provide the names and student IDs of the team-members (Maximum 2 person) in the field \"Team mates\" below. If you are not working in a team please insert only your name and student ID. \n",
        "\n",
        "- The accepted submission formats are Colab links or .ipynb files. If you are submitting Colab links please make sure that the privacy settings for the file is public so we can access your code. \n",
        "\n",
        "- The submission will automatically close on <font color='red'>**17 November at 23:59**</font>, so please make sure to submit before the deadline. \n",
        "\n",
        "- ONLY one of the teammates should submit the homework. We will grade the homework and the marks and feedback is applied for both the team members. So please communicate with your team member about marks and feedback if you are submit the homework.\n",
        "\n",
        "- If a question is not clear, please ask us in Moodle ONLY. \n",
        "\n",
        "- For coding related questions, do submit your code as well as your explanation/answer.\n",
        "\n",
        "- After you have finished solving the Homework, please restart the Kernel and run all the cells to check if there is any persisting issues. \n",
        "\n",
        "- Plagiarism is <font color='red'>**PROHIBITED**</font>. Any form of plagiarism will be dealt according to the university policy (https://www.ut.ee/en/current-students/academic-fraud).\n",
        "\n",
        "- Please <font color='red'>do not change</font> the template of this notebook file. You can download the .ipynb file and work on that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHQxPUoeGB8T"
      },
      "source": [
        "## Question 1 (5 points)\n",
        "\n",
        "You are going to predict whether an employee is about to leave the company using HR_Employee_Attrition.csv dataset. We are predicting  Attrition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Dw3zu-iNyH2"
      },
      "source": [
        "HR_Employee_Attrition.csv data contains the information about employees in a company.\n",
        "1. **Age** – self descriptive\n",
        "2. **BusinessTravel** – how frequent employee travels\n",
        "3. **DailyRate** – self descriptive\n",
        "4. **Department** – self descriptive\n",
        "5. **DistanceFromHome** – distance between employee home and work\n",
        "6. **Education** – education level of employee\n",
        "7. **EducationField** – self descriptive\n",
        "8. **EnvironmentSatisfaction** – level of satisfaction with working environment\n",
        "9. **Gender** – self descriptive\n",
        "10. **HourlyRate** – self descriptive\n",
        "11. **JobRole** – self descriptive\n",
        "12. **JobInvolvement** – level of interest of the job\n",
        "13. **JobSatisfaction** – level of satisfaction with current job\n",
        "14. **MaritalStatus** – self descriptive\n",
        "15. **MonthlyIncome** – self descriptive\n",
        "16. **MonthlyRate** – self descriptive\n",
        "17. **NumCompaniesWorked** – self descriptive\n",
        "18. **Over18** – whether customer age is more than 18\n",
        "19. **OverTime** – whether customer works overtime or not\n",
        "20. **PerformanceRating** – performance level of employee\n",
        "21. **RelationshipSatisfaction** – level of satisfaction with working community\n",
        "22. **StandardHours** – standard amount of hours that employee works\n",
        "23. **TotalWorkingYears** – whether customer age is more than 18\n",
        "24. **TrainingTimesLastYear**– whether customer age is more than \n",
        "25. **18WorkLifeBalance** – level of satisfaction with employee’s work time and free time proportions\n",
        "26. **YearsAtCompany** – self descriptive\n",
        "27. **YearsInCurrentRole** – self descriptive\n",
        "28. **YearsSinceLastPromotion** – self descriptive\n",
        "29. **YearsWithCurrManager** – self descriptive\n",
        "30. **Attrition** – predicting variable which signify whether customer has left (Yes) the company or not (No)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKeV44RyNyH4"
      },
      "source": [
        "###Question 1.1 (1 point):\n",
        "Prepare the dataset \n",
        "\n",
        "    * Check if there is any missing and NULL values. \n",
        "    * Check the Over18 column. What do you think we should do with this column?\n",
        "    * Convert Attrition column to numeric (similar to what we did in HW3 Q2.1)\n",
        "    * Convert BusinessTravel, Department, EducationField, Gender, JobRole, MaritalStatus, OverTime columns into dummy variables (also called One-Hot-Encoding method). You can find an example in the lab session, the function we used is pd.get_dummies().\n",
        "    * Scale all the columns to a range from 0 to 1 (use MinMaxScaler)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eriHAlsey10"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSv3DCOPevvk"
      },
      "source": [
        "###Question 1.2 (2 points):\n",
        " Using any of the two classification models of your choice (out of models used during the lab session: random forest, logistic regression, SVM, XGboost, ADABoost) predict the Attrition. Make 80/20 train-test split and set the random_state = 0 (for some algorithms it is also called random_seed), so we could reproduce the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuO8Nsfcf1Iv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhQAgpRzfPX0"
      },
      "source": [
        "###Question 1.3 (2 points):\n",
        "Compare those two models based on precision, recall, F1 score, accuracy, and ROCAUC metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8fRjfU0gFbS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqbFLv_v7uHE"
      },
      "source": [
        "## Question 2 (1 point)\n",
        "\n",
        "One of the most known problems in classification tasks is imbalance of labels in data. \n",
        "1.  Read the [Dealing with Imbalanced Data](https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18) article and summarize the available methods to tackle the Imbalanced Classes. (0.8p) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5j1-WopCgfHD"
      },
      "source": [
        "2. Check \"HR_Employee_Attrition.csv\" dataset. Based on the label (Attrition column), you think the dataset is balanced? (0.2p) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJRELwbogggp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8dR8saCgn4s"
      },
      "source": [
        "## Question 3 (2 points)\n",
        "\n",
        "This task requires a bit more than what was covered during the lab session. The only new thing here is modification of the training set, and the code example is present below. All the rest steps are the same as for models training/evaluation done during the lab session and Q1 above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50TdPT6hNyIE"
      },
      "source": [
        "### Question 3.1 (0.5 point)\n",
        "Undersample the majority class in \"HR_Employee_Attrition.csv\" dataset so that the data becomes balanced. Take X_train, y_train, X_test, y_test used in Q1. You have to undersample ONLY ***X_train*** and ***y_train***, keep *X_test* and *y_test* unchanged. You can use the code from the [Dealing with Imbalanced Data](https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18) article or the following code using [imblearn package](https://pypi.org/project/imblearn/):\n",
        "\n",
        "`from imblearn.under_sampling import RandomUnderSampler`\n",
        "\n",
        "`undersampler = RandomUnderSampler(random_state=0)`\n",
        "\n",
        "`X_train_undersampled, y_train_undersampled = undersampler.fit_resample(X_train, y_train)`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVikhQa_jVKL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmV9thDAgrQj"
      },
      "source": [
        "\n",
        "\n",
        "### Question 3.2 (1.5 point)\n",
        "Use the same two classification algorithms that you have chosen in the Q1 on your new undersampled train set. Compare the performance of models trained on undersampled data with models from Q1 (trained on non-undersampled data). By comparing results we mean compare precision, recall, F1 score, accuracy, and ROCAUC. \n",
        "\n",
        "So, if for Q1 you've chosen Logistic Regression (LR) and SVM, then train LR and SVM on undersampled data. Then compare LR trained on undersampled with LR trained on non-undersampled data and SVM trained on undersampled with SVM trained on non-undersampled data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGU6OuxYjV1L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "743sNZr0ChfJ"
      },
      "source": [
        "## Question 4 (2 points)\n",
        "\n",
        "### Question 4.1 (0.5 point) \n",
        "Oversample the minority class in \"HR_Employee_Attrition.csv\" dataset so that the data becomes balanced. Take X_train, y_train, X_test, y_test used in Q1. You have to oversample **ONLY** ***X_train*** and ***y_train***, keep *X_test* and *y_test* unchanged. You can use the code from the [Dealing with Imbalanced Data](https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18) article or the following code using [imblearn package](https://pypi.org/project/imblearn/):\n",
        "\n",
        "`from imblearn.over_sampling import RandomOverSampler`\n",
        "\n",
        "`oversampler = RandomOverSampler(random_state=0)`\n",
        "\n",
        "`X_train_oversampled, y_train_oversampled = oversampler.fit_resample(X_train, y_train)`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAQa74r9hQTx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AverPH4ehOQz"
      },
      "source": [
        "\n",
        "### Question 4.2 (1.5 point)\n",
        " Use the same two classification algorithms that you have chosen in the Q1 on your new oversampled train set. Compare the performance of models trained on oversampled data with models from Q1 (trained on non-oversampled data). By comparing results we mean compare precision, recall, F1 score, accuracy, and ROCAUC. \n",
        "\n",
        "So, if for Q1 you've chosen Logistic Regression (LR) and SVM, then train LR and SVM on oversampled data. Then compare LR trained on oversampled with LR trained on non-oversampled data and SVM trained on oversampled with SVM trained on non-oversampled data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkW7_kl4hP5S"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc0BZVzs0ftg"
      },
      "source": [
        "# How complicate the homework was (from 0 to 10)?|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COkdaj3U0jIx"
      },
      "source": [
        "# How many hours you spent for this homework?"
      ]
    }
  ]
}