{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "BDA2021Fall_HW5_Raivo_Kasepuu_Maarja_Parve.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RaivoKasepuu/BDA_Tartu_MTAT_03_319/blob/master/BDA2021Fall_HW5_Raivo_Kasepuu_Maarja_Parve.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peLGGRdTeci0"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\"><b></b>\n",
        "<h1><center> <font color='black'> Homework 05  </font></center></h1>\n",
        "<h2><center> <font color='black'> Customer lifecycle management: Attrition Prediction - Classification </font></center></h2>   \n",
        "<h2><center> <font color='black'> MTAT.03.319 - Business Data Analytics</font></center></h2>\n",
        "<h2><center> <font color='black'> University of Tartu - Fall 2021</font></center></h2>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEIS8WGK0dfw"
      },
      "source": [
        "# Homework instructions\n",
        "- Please name your homeworks in the following format **BDAFall2021_HWX_Name_Surname.ipynb** then it will be easier to grade your homeworks and smaller possibility for a human mistake.\n",
        "- Please provide the names and student IDs of the team-members (Maximum 2 person) in the field \"Team mates\" below. If you are not working in a team please insert only your name and student ID. \n",
        "\n",
        "- The accepted submission formats are Colab links or .ipynb files. If you are submitting Colab links please make sure that the privacy settings for the file is public so we can access your code. \n",
        "\n",
        "- The submission will automatically close on <font color='red'>**17 November at 23:59**</font>, so please make sure to submit before the deadline. \n",
        "\n",
        "- ONLY one of the teammates should submit the homework. We will grade the homework and the marks and feedback is applied for both the team members. So please communicate with your team member about marks and feedback if you are submit the homework.\n",
        "\n",
        "- If a question is not clear, please ask us in Moodle ONLY. \n",
        "\n",
        "- For coding related questions, do submit your code as well as your explanation/answer.\n",
        "\n",
        "- After you have finished solving the Homework, please restart the Kernel and run all the cells to check if there is any persisting issues. \n",
        "\n",
        "- Plagiarism is <font color='red'>**PROHIBITED**</font>. Any form of plagiarism will be dealt according to the university policy (https://www.ut.ee/en/current-students/academic-fraud).\n",
        "\n",
        "- Please <font color='red'>do not change</font> the template of this notebook file. You can download the .ipynb file and work on that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpHZwAFsS28F"
      },
      "source": [
        "**<h2><font color='red'>Team mates:</font></h2>**\n",
        "\n",
        "\n",
        "<font color='red'>Name: Raivo Kasepuu </font>&emsp;   <font color='red'>Student ID: B710710</font>\n",
        "\n",
        "\n",
        "<font color='red'>Name: Maarja Parve</font>&emsp;   <font color='red'>Student ID: B99902</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHQxPUoeGB8T"
      },
      "source": [
        "## Question 1 (5 points)\n",
        "\n",
        "You are going to predict whether an employee is about to leave the company using HR_Employee_Attrition.csv dataset. We are predicting  Attrition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Dw3zu-iNyH2"
      },
      "source": [
        "HR_Employee_Attrition.csv data contains the information about employees in a company.\n",
        "1. **Age** – self descriptive\n",
        "2. **BusinessTravel** – how frequent employee travels\n",
        "3. **DailyRate** – self descriptive\n",
        "4. **Department** – self descriptive\n",
        "5. **DistanceFromHome** – distance between employee home and work\n",
        "6. **Education** – education level of employee\n",
        "7. **EducationField** – self descriptive\n",
        "8. **EnvironmentSatisfaction** – level of satisfaction with working environment\n",
        "9. **Gender** – self descriptive\n",
        "10. **HourlyRate** – self descriptive\n",
        "11. **JobRole** – self descriptive\n",
        "12. **JobInvolvement** – level of interest of the job\n",
        "13. **JobSatisfaction** – level of satisfaction with current job\n",
        "14. **MaritalStatus** – self descriptive\n",
        "15. **MonthlyIncome** – self descriptive\n",
        "16. **MonthlyRate** – self descriptive\n",
        "17. **NumCompaniesWorked** – self descriptive\n",
        "18. **Over18** – whether customer age is more than 18\n",
        "19. **OverTime** – whether customer works overtime or not\n",
        "20. **PerformanceRating** – performance level of employee\n",
        "21. **RelationshipSatisfaction** – level of satisfaction with working community\n",
        "22. **StandardHours** – standard amount of hours that employee works\n",
        "23. **TotalWorkingYears** – whether customer age is more than 18\n",
        "24. **TrainingTimesLastYear**– whether customer age is more than \n",
        "25. **18WorkLifeBalance** – level of satisfaction with employee’s work time and free time proportions\n",
        "26. **YearsAtCompany** – self descriptive\n",
        "27. **YearsInCurrentRole** – self descriptive\n",
        "28. **YearsSinceLastPromotion** – self descriptive\n",
        "29. **YearsWithCurrManager** – self descriptive\n",
        "30. **Attrition** – predicting variable which signify whether customer has left (Yes) the company or not (No)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKeV44RyNyH4"
      },
      "source": [
        "###Question 1.1 (1 point):\n",
        "Prepare the dataset \n",
        "\n",
        "    * Check if there is any missing and NULL values. \n",
        "    * Check the Over18 column. What do you think we should do with this column?\n",
        "    * Convert Attrition column to numeric (similar to what we did in HW3 Q2.1)\n",
        "    * Convert BusinessTravel, Department, EducationField, Gender, JobRole, MaritalStatus, OverTime columns into dummy variables (also called One-Hot-Encoding method). You can find an example in the lab session, the function we used is pd.get_dummies().\n",
        "    * Scale all the columns to a range from 0 to 1 (use MinMaxScaler)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eriHAlsey10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "767a5971-d5c1-42e2-d7a6-602d3b2d8cb7"
      },
      "source": [
        "print(\"Hello! Welcome to our HW5\")\n",
        "print(\"Maarja and Raivo are ready for the 5th challenge!\")\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.ticker as mtick\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#print(\"Let's make the notebook reproducible:\")\n",
        "#np.random.seed(42)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! Welcome to our HW5\n",
            "Maarja and Raivo are ready for the 5th challenge!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O40dWeIjTLCU",
        "outputId": "6f83d29f-57d3-44d9-83ff-2a7f774372fc"
      },
      "source": [
        "print(\"Lets check out, what dataset file we got this time\")\n",
        "df = pd.read_csv('HR_Employee_Attrition.csv')\n",
        "df.columns.values\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lets check out, what dataset file we got this time\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Age', 'Attrition', 'BusinessTravel', 'DailyRate', 'Department',\n",
              "       'DistanceFromHome', 'Education', 'EducationField',\n",
              "       'EnvironmentSatisfaction', 'Gender', 'HourlyRate',\n",
              "       'JobInvolvement', 'JobRole', 'JobSatisfaction', 'MaritalStatus',\n",
              "       'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'Over18',\n",
              "       'OverTime', 'PerformanceRating', 'RelationshipSatisfaction',\n",
              "       'StandardHours', 'TotalWorkingYears', 'TrainingTimesLastYear',\n",
              "       'WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole',\n",
              "       'YearsSinceLastPromotion', 'YearsWithCurrManager'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luxgC8seHLHv",
        "outputId": "81591f08-347e-4322-ab8d-2ca56011639e"
      },
      "source": [
        "print(\"Let's check if there are any NULL values\")\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's check if there are any NULL values\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1470 entries, 0 to 1469\n",
            "Data columns (total 30 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   Age                       1470 non-null   int64 \n",
            " 1   Attrition                 1470 non-null   object\n",
            " 2   BusinessTravel            1470 non-null   object\n",
            " 3   DailyRate                 1470 non-null   int64 \n",
            " 4   Department                1470 non-null   object\n",
            " 5   DistanceFromHome          1470 non-null   int64 \n",
            " 6   Education                 1470 non-null   int64 \n",
            " 7   EducationField            1470 non-null   object\n",
            " 8   EnvironmentSatisfaction   1470 non-null   int64 \n",
            " 9   Gender                    1470 non-null   object\n",
            " 10  HourlyRate                1470 non-null   int64 \n",
            " 11  JobInvolvement            1470 non-null   int64 \n",
            " 12  JobRole                   1470 non-null   object\n",
            " 13  JobSatisfaction           1470 non-null   int64 \n",
            " 14  MaritalStatus             1470 non-null   object\n",
            " 15  MonthlyIncome             1470 non-null   int64 \n",
            " 16  MonthlyRate               1470 non-null   int64 \n",
            " 17  NumCompaniesWorked        1470 non-null   int64 \n",
            " 18  Over18                    1470 non-null   object\n",
            " 19  OverTime                  1470 non-null   object\n",
            " 20  PerformanceRating         1470 non-null   int64 \n",
            " 21  RelationshipSatisfaction  1470 non-null   int64 \n",
            " 22  StandardHours             1470 non-null   int64 \n",
            " 23  TotalWorkingYears         1470 non-null   int64 \n",
            " 24  TrainingTimesLastYear     1470 non-null   int64 \n",
            " 25  WorkLifeBalance           1470 non-null   int64 \n",
            " 26  YearsAtCompany            1470 non-null   int64 \n",
            " 27  YearsInCurrentRole        1470 non-null   int64 \n",
            " 28  YearsSinceLastPromotion   1470 non-null   int64 \n",
            " 29  YearsWithCurrManager      1470 non-null   int64 \n",
            "dtypes: int64(21), object(9)\n",
            "memory usage: 344.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjggSxvDBbXG",
        "outputId": "c8d1006c-05db-456e-b439-0ae8aaea89b6"
      },
      "source": [
        "print(\"Let's check if there is any values missing\")\n",
        "df.isnull().sum()\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"There is no non-null or missing values\")\n",
        "#df.dropna(inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's check if there is any values missing\n",
            "\n",
            "There is no non-null or missing values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "60PL3UDkXara",
        "outputId": "96b821d2-6fa6-41be-d1e7-606ee0b85c60"
      },
      "source": [
        "print(\"Let's check the Over18 column\")\n",
        "print(\"Over18 column has only one unique value so it adds no information and we could drop the column\")\n",
        "df.describe(include='all')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's check the Over18 column\n",
            "Over18 column has only one unique value so it adds no information and we could drop the column\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Attrition</th>\n",
              "      <th>BusinessTravel</th>\n",
              "      <th>DailyRate</th>\n",
              "      <th>Department</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EducationField</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>Gender</th>\n",
              "      <th>HourlyRate</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>JobRole</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>MaritalStatus</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>MonthlyRate</th>\n",
              "      <th>NumCompaniesWorked</th>\n",
              "      <th>Over18</th>\n",
              "      <th>OverTime</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StandardHours</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1470.000000</td>\n",
              "      <td>1470</td>\n",
              "      <td>1470</td>\n",
              "      <td>1470.000000</td>\n",
              "      <td>1470</td>\n",
              "      <td>1470.000000</td>\n",
              "      <td>1470.000000</td>\n",
              "      <td>1470</td>\n",
              "      <td>1470.000000</td>\n",
              "      <td>1470</td>\n",
              "      <td>1470.000000</td>\n",
              "      <td>1470.000000</td>\n",
              "      <td>1470</td>\n",
              "      <td>1470.000000</td>\n",
              "      <td>1470</td>\n",
              "      <td>1470.000000</td>\n",
              "      <td>1470.000000</td>\n",
              "      <td>1470.000000</td>\n",
              "      <td>1470</td>\n",
              "      <td>1470</td>\n",
              "      <td>1470.000000</td>\n",
              "      <td>1470.000000</td>\n",
              "      <td>1470.0</td>\n",
              "      <td>1470.000000</td>\n",
              "      <td>1470.000000</td>\n",
              "      <td>1470.000000</td>\n",
              "      <td>1470.000000</td>\n",
              "      <td>1470.000000</td>\n",
              "      <td>1470.000000</td>\n",
              "      <td>1470.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Life Sciences</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Male</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Sales Executive</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Married</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Y</td>\n",
              "      <td>No</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1233</td>\n",
              "      <td>1043</td>\n",
              "      <td>NaN</td>\n",
              "      <td>961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>606</td>\n",
              "      <td>NaN</td>\n",
              "      <td>882</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>326</td>\n",
              "      <td>NaN</td>\n",
              "      <td>673</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1470</td>\n",
              "      <td>1054</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>36.923810</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>802.485714</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.192517</td>\n",
              "      <td>2.912925</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.721769</td>\n",
              "      <td>NaN</td>\n",
              "      <td>65.891156</td>\n",
              "      <td>2.729932</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.728571</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6502.931293</td>\n",
              "      <td>14313.103401</td>\n",
              "      <td>2.693197</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.153741</td>\n",
              "      <td>2.712245</td>\n",
              "      <td>80.0</td>\n",
              "      <td>11.279592</td>\n",
              "      <td>2.799320</td>\n",
              "      <td>2.761224</td>\n",
              "      <td>7.008163</td>\n",
              "      <td>4.229252</td>\n",
              "      <td>2.187755</td>\n",
              "      <td>4.123129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.135373</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>403.509100</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.106864</td>\n",
              "      <td>1.024165</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.093082</td>\n",
              "      <td>NaN</td>\n",
              "      <td>20.329428</td>\n",
              "      <td>0.711561</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.102846</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4707.956783</td>\n",
              "      <td>7117.786044</td>\n",
              "      <td>2.498009</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.360824</td>\n",
              "      <td>1.081209</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.780782</td>\n",
              "      <td>1.289271</td>\n",
              "      <td>0.706476</td>\n",
              "      <td>6.126525</td>\n",
              "      <td>3.623137</td>\n",
              "      <td>3.222430</td>\n",
              "      <td>3.568136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>18.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>102.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1009.000000</td>\n",
              "      <td>2094.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>30.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>465.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2911.000000</td>\n",
              "      <td>8047.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>80.0</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>36.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>802.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4919.000000</td>\n",
              "      <td>14235.500000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>80.0</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>43.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1157.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>83.750000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8379.000000</td>\n",
              "      <td>20461.500000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>80.0</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>60.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1499.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19999.000000</td>\n",
              "      <td>26999.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>80.0</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>17.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                Age Attrition  ... YearsSinceLastPromotion  YearsWithCurrManager\n",
              "count   1470.000000      1470  ...             1470.000000           1470.000000\n",
              "unique          NaN         2  ...                     NaN                   NaN\n",
              "top             NaN        No  ...                     NaN                   NaN\n",
              "freq            NaN      1233  ...                     NaN                   NaN\n",
              "mean      36.923810       NaN  ...                2.187755              4.123129\n",
              "std        9.135373       NaN  ...                3.222430              3.568136\n",
              "min       18.000000       NaN  ...                0.000000              0.000000\n",
              "25%       30.000000       NaN  ...                0.000000              2.000000\n",
              "50%       36.000000       NaN  ...                1.000000              3.000000\n",
              "75%       43.000000       NaN  ...                3.000000              7.000000\n",
              "max       60.000000       NaN  ...               15.000000             17.000000\n",
              "\n",
              "[11 rows x 30 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gm3qaAcpKCdc",
        "outputId": "e7fe894d-4648-45f8-aa6f-247397b97cc2"
      },
      "source": [
        "print(\"Deleting the Over18 column:\")\n",
        "df=df.drop(columns=['Over18'])\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"We now have one column less\")\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting the Over18 column:\n",
            "\n",
            "We now have one column less\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1470 entries, 0 to 1469\n",
            "Data columns (total 29 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   Age                       1470 non-null   int64 \n",
            " 1   Attrition                 1470 non-null   object\n",
            " 2   BusinessTravel            1470 non-null   object\n",
            " 3   DailyRate                 1470 non-null   int64 \n",
            " 4   Department                1470 non-null   object\n",
            " 5   DistanceFromHome          1470 non-null   int64 \n",
            " 6   Education                 1470 non-null   int64 \n",
            " 7   EducationField            1470 non-null   object\n",
            " 8   EnvironmentSatisfaction   1470 non-null   int64 \n",
            " 9   Gender                    1470 non-null   object\n",
            " 10  HourlyRate                1470 non-null   int64 \n",
            " 11  JobInvolvement            1470 non-null   int64 \n",
            " 12  JobRole                   1470 non-null   object\n",
            " 13  JobSatisfaction           1470 non-null   int64 \n",
            " 14  MaritalStatus             1470 non-null   object\n",
            " 15  MonthlyIncome             1470 non-null   int64 \n",
            " 16  MonthlyRate               1470 non-null   int64 \n",
            " 17  NumCompaniesWorked        1470 non-null   int64 \n",
            " 18  OverTime                  1470 non-null   object\n",
            " 19  PerformanceRating         1470 non-null   int64 \n",
            " 20  RelationshipSatisfaction  1470 non-null   int64 \n",
            " 21  StandardHours             1470 non-null   int64 \n",
            " 22  TotalWorkingYears         1470 non-null   int64 \n",
            " 23  TrainingTimesLastYear     1470 non-null   int64 \n",
            " 24  WorkLifeBalance           1470 non-null   int64 \n",
            " 25  YearsAtCompany            1470 non-null   int64 \n",
            " 26  YearsInCurrentRole        1470 non-null   int64 \n",
            " 27  YearsSinceLastPromotion   1470 non-null   int64 \n",
            " 28  YearsWithCurrManager      1470 non-null   int64 \n",
            "dtypes: int64(21), object(8)\n",
            "memory usage: 333.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj4nvc-UZt4D",
        "outputId": "e5e37945-9b60-49e3-b05a-c2d1b02a634e"
      },
      "source": [
        "print(\"Converting Attrition column to numeric\")\n",
        "print(\"function for changing values:\")\n",
        "\n",
        "df['Attrition'].replace(to_replace=\"Yes\", value=1, inplace=True)\n",
        "df['Attrition'].replace(to_replace=\"No\", value=0, inplace=True)\n",
        "print()\n",
        "\n",
        "df.head()\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting Attrition column to numeric\n",
            "function for changing values:\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1470 entries, 0 to 1469\n",
            "Data columns (total 29 columns):\n",
            " #   Column                    Non-Null Count  Dtype \n",
            "---  ------                    --------------  ----- \n",
            " 0   Age                       1470 non-null   int64 \n",
            " 1   Attrition                 1470 non-null   int64 \n",
            " 2   BusinessTravel            1470 non-null   object\n",
            " 3   DailyRate                 1470 non-null   int64 \n",
            " 4   Department                1470 non-null   object\n",
            " 5   DistanceFromHome          1470 non-null   int64 \n",
            " 6   Education                 1470 non-null   int64 \n",
            " 7   EducationField            1470 non-null   object\n",
            " 8   EnvironmentSatisfaction   1470 non-null   int64 \n",
            " 9   Gender                    1470 non-null   object\n",
            " 10  HourlyRate                1470 non-null   int64 \n",
            " 11  JobInvolvement            1470 non-null   int64 \n",
            " 12  JobRole                   1470 non-null   object\n",
            " 13  JobSatisfaction           1470 non-null   int64 \n",
            " 14  MaritalStatus             1470 non-null   object\n",
            " 15  MonthlyIncome             1470 non-null   int64 \n",
            " 16  MonthlyRate               1470 non-null   int64 \n",
            " 17  NumCompaniesWorked        1470 non-null   int64 \n",
            " 18  OverTime                  1470 non-null   object\n",
            " 19  PerformanceRating         1470 non-null   int64 \n",
            " 20  RelationshipSatisfaction  1470 non-null   int64 \n",
            " 21  StandardHours             1470 non-null   int64 \n",
            " 22  TotalWorkingYears         1470 non-null   int64 \n",
            " 23  TrainingTimesLastYear     1470 non-null   int64 \n",
            " 24  WorkLifeBalance           1470 non-null   int64 \n",
            " 25  YearsAtCompany            1470 non-null   int64 \n",
            " 26  YearsInCurrentRole        1470 non-null   int64 \n",
            " 27  YearsSinceLastPromotion   1470 non-null   int64 \n",
            " 28  YearsWithCurrManager      1470 non-null   int64 \n",
            "dtypes: int64(22), object(7)\n",
            "memory usage: 333.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ADlSIgmbJsU",
        "outputId": "8992aaab-160e-4d34-af47-f9cd71e27510"
      },
      "source": [
        "print(\"Converting BusinessTravel, Department, EducationField, Gender, JobRole, MaritalStatus, OverTime columns into dummy variables\")\n",
        "print(\"Using the dummy function:\")\n",
        "df_dummies = pd.get_dummies(df, columns=['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole', 'MaritalStatus', 'OverTime'])\n",
        "\n",
        "df_dummies.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting BusinessTravel, Department, EducationField, Gender, JobRole, MaritalStatus, OverTime columns into dummy variables\n",
            "Using the dummy function:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1470 entries, 0 to 1469\n",
            "Data columns (total 50 columns):\n",
            " #   Column                             Non-Null Count  Dtype\n",
            "---  ------                             --------------  -----\n",
            " 0   Age                                1470 non-null   int64\n",
            " 1   Attrition                          1470 non-null   int64\n",
            " 2   DailyRate                          1470 non-null   int64\n",
            " 3   DistanceFromHome                   1470 non-null   int64\n",
            " 4   Education                          1470 non-null   int64\n",
            " 5   EnvironmentSatisfaction            1470 non-null   int64\n",
            " 6   HourlyRate                         1470 non-null   int64\n",
            " 7   JobInvolvement                     1470 non-null   int64\n",
            " 8   JobSatisfaction                    1470 non-null   int64\n",
            " 9   MonthlyIncome                      1470 non-null   int64\n",
            " 10  MonthlyRate                        1470 non-null   int64\n",
            " 11  NumCompaniesWorked                 1470 non-null   int64\n",
            " 12  PerformanceRating                  1470 non-null   int64\n",
            " 13  RelationshipSatisfaction           1470 non-null   int64\n",
            " 14  StandardHours                      1470 non-null   int64\n",
            " 15  TotalWorkingYears                  1470 non-null   int64\n",
            " 16  TrainingTimesLastYear              1470 non-null   int64\n",
            " 17  WorkLifeBalance                    1470 non-null   int64\n",
            " 18  YearsAtCompany                     1470 non-null   int64\n",
            " 19  YearsInCurrentRole                 1470 non-null   int64\n",
            " 20  YearsSinceLastPromotion            1470 non-null   int64\n",
            " 21  YearsWithCurrManager               1470 non-null   int64\n",
            " 22  BusinessTravel_Non-Travel          1470 non-null   uint8\n",
            " 23  BusinessTravel_Travel_Frequently   1470 non-null   uint8\n",
            " 24  BusinessTravel_Travel_Rarely       1470 non-null   uint8\n",
            " 25  Department_Human Resources         1470 non-null   uint8\n",
            " 26  Department_Research & Development  1470 non-null   uint8\n",
            " 27  Department_Sales                   1470 non-null   uint8\n",
            " 28  EducationField_Human Resources     1470 non-null   uint8\n",
            " 29  EducationField_Life Sciences       1470 non-null   uint8\n",
            " 30  EducationField_Marketing           1470 non-null   uint8\n",
            " 31  EducationField_Medical             1470 non-null   uint8\n",
            " 32  EducationField_Other               1470 non-null   uint8\n",
            " 33  EducationField_Technical Degree    1470 non-null   uint8\n",
            " 34  Gender_Female                      1470 non-null   uint8\n",
            " 35  Gender_Male                        1470 non-null   uint8\n",
            " 36  JobRole_Healthcare Representative  1470 non-null   uint8\n",
            " 37  JobRole_Human Resources            1470 non-null   uint8\n",
            " 38  JobRole_Laboratory Technician      1470 non-null   uint8\n",
            " 39  JobRole_Manager                    1470 non-null   uint8\n",
            " 40  JobRole_Manufacturing Director     1470 non-null   uint8\n",
            " 41  JobRole_Research Director          1470 non-null   uint8\n",
            " 42  JobRole_Research Scientist         1470 non-null   uint8\n",
            " 43  JobRole_Sales Executive            1470 non-null   uint8\n",
            " 44  JobRole_Sales Representative       1470 non-null   uint8\n",
            " 45  MaritalStatus_Divorced             1470 non-null   uint8\n",
            " 46  MaritalStatus_Married              1470 non-null   uint8\n",
            " 47  MaritalStatus_Single               1470 non-null   uint8\n",
            " 48  OverTime_No                        1470 non-null   uint8\n",
            " 49  OverTime_Yes                       1470 non-null   uint8\n",
            "dtypes: int64(22), uint8(28)\n",
            "memory usage: 293.0 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "AeifQM_WCmM0",
        "outputId": "fd778e66-143c-4354-cfd3-51d3c7b5e5b8"
      },
      "source": [
        "print(\"Let's scale all the columns to a range from 0 to 1\")\n",
        "#MinMaxScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        " \n",
        "#standardization of dependent variables\n",
        "\n",
        "features = df_dummies.columns.values\n",
        "scaler = MinMaxScaler(feature_range = (0,1))\n",
        "scaler.fit(df_dummies)\n",
        "df_dummies = pd.DataFrame(scaler.transform(df_dummies))\n",
        "df_dummies.columns = features\n",
        "\n",
        "df_dummies.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's scale all the columns to a range from 0 to 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Attrition</th>\n",
              "      <th>DailyRate</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>HourlyRate</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>MonthlyRate</th>\n",
              "      <th>NumCompaniesWorked</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>RelationshipSatisfaction</th>\n",
              "      <th>StandardHours</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsInCurrentRole</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "      <th>BusinessTravel_Non-Travel</th>\n",
              "      <th>BusinessTravel_Travel_Frequently</th>\n",
              "      <th>BusinessTravel_Travel_Rarely</th>\n",
              "      <th>Department_Human Resources</th>\n",
              "      <th>Department_Research &amp; Development</th>\n",
              "      <th>Department_Sales</th>\n",
              "      <th>EducationField_Human Resources</th>\n",
              "      <th>EducationField_Life Sciences</th>\n",
              "      <th>EducationField_Marketing</th>\n",
              "      <th>EducationField_Medical</th>\n",
              "      <th>EducationField_Other</th>\n",
              "      <th>EducationField_Technical Degree</th>\n",
              "      <th>Gender_Female</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>JobRole_Healthcare Representative</th>\n",
              "      <th>JobRole_Human Resources</th>\n",
              "      <th>JobRole_Laboratory Technician</th>\n",
              "      <th>JobRole_Manager</th>\n",
              "      <th>JobRole_Manufacturing Director</th>\n",
              "      <th>JobRole_Research Director</th>\n",
              "      <th>JobRole_Research Scientist</th>\n",
              "      <th>JobRole_Sales Executive</th>\n",
              "      <th>JobRole_Sales Representative</th>\n",
              "      <th>MaritalStatus_Divorced</th>\n",
              "      <th>MaritalStatus_Married</th>\n",
              "      <th>MaritalStatus_Single</th>\n",
              "      <th>OverTime_No</th>\n",
              "      <th>OverTime_Yes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.547619</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.715820</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.262454</td>\n",
              "      <td>0.698053</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.126700</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.442857</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.217009</td>\n",
              "      <td>0.916001</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.250</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.452381</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.909807</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.25</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.056925</td>\n",
              "      <td>0.012126</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.175</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.357143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.923407</td>\n",
              "      <td>0.071429</td>\n",
              "      <td>0.75</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.371429</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.100053</td>\n",
              "      <td>0.845814</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.200</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.388889</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.350036</td>\n",
              "      <td>0.035714</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.129489</td>\n",
              "      <td>0.583738</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.150</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Age  Attrition  ...  OverTime_No  OverTime_Yes\n",
              "0  0.547619        1.0  ...          0.0           1.0\n",
              "1  0.738095        0.0  ...          1.0           0.0\n",
              "2  0.452381        1.0  ...          0.0           1.0\n",
              "3  0.357143        0.0  ...          0.0           1.0\n",
              "4  0.214286        0.0  ...          1.0           0.0\n",
              "\n",
              "[5 rows x 50 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSv3DCOPevvk"
      },
      "source": [
        "###Question 1.2 (2 points):\n",
        " Using any of the two classification models of your choice (out of models used during the lab session: random forest, logistic regression, SVM, XGboost, ADABoost) predict the Attrition. Make 80/20 train-test split and set the random_state = 0 (for some algorithms it is also called random_seed), so we could reproduce the results.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuO8Nsfcf1Iv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f42d0977-cb4a-4a51-d61e-6a7f9c985490"
      },
      "source": [
        "print(\"First let's determine the variables to predict the Attrition:\")\n",
        "y = df_dummies[\"Attrition\"].values\n",
        "X = df_dummies.drop(columns=[\"Attrition\"])\n",
        "\n",
        "print(\"At first we need to create Train & Test Data with 80/20 train-test split and the random_state = 0\")\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First let's determine the variables to predict the Attrition:\n",
            "At first we need to create Train & Test Data with 80/20 train-test split and the random_state = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi18djbSTAQc",
        "outputId": "d5cbac1b-0cc7-4708-9462-07f5e5941515"
      },
      "source": [
        "print(\"As the first model let's run the logistic regression model:\")\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression()\n",
        "result = model.fit(X_train, y_train)\n",
        "from sklearn import metrics\n",
        "Model1_prediction = model.predict(X_test)\n",
        "\n",
        "accuracy_LR = model.score(X_test, y_test)\n",
        "\n",
        "#print(\"Accuracy of logistic regression classifier on test set: {:.2f}\".format(accuracy_LR))\n",
        "\n",
        "print()\n",
        "#from sklearn.metrics import classification_report\n",
        "#print(classification_report(y_test,Model1_prediction))\n",
        "precision_LR = metrics.precision_score(y_test, Model1_prediction)\n",
        "recall_LR = metrics.recall_score(y_test, Model1_prediction)\n",
        "f1_score_LR = metrics.f1_score(y_test, Model1_prediction)\n",
        "\n",
        "probs = model.predict_proba(X_test)\n",
        "class_1_probs = probs[:,1]\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, class_1_probs)\n",
        "roc_auc_LR = metrics.auc(fpr, tpr)\n",
        "print(\"ROCAUC_LR: \", roc_auc_LR)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As the first model let's run the logistic regression model:\n",
            "\n",
            "ROCAUC_LR:  0.8569762598917118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JLau7H_NKJm",
        "outputId": "8bd9c4bb-8cd0-4a77-8248-3f7bbbf999c6"
      },
      "source": [
        "print(\"As the second model let's run the Random Forest model:\")\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "model_rf = RandomForestClassifier(n_estimators=1000 , oob_score = True, n_jobs = -1,\n",
        "                                  random_state =50, max_features = \"auto\",\n",
        "                                  max_leaf_nodes = 30)\n",
        "model_rf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "Model2_prediction = model_rf.predict(X_test)\n",
        "accuracy_RF = metrics.accuracy_score(y_test, Model2_prediction)\n",
        "\n",
        "\n",
        "probs = model_rf.predict_proba(X_test)\n",
        "class_1_probs = probs[:,1]\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, class_1_probs)\n",
        "roc_auc_RF = metrics.auc(fpr, tpr)\n",
        "\n",
        "precision_RF = metrics.precision_score(y_test, Model2_prediction)\n",
        "recall_RF = metrics.recall_score(y_test, Model2_prediction)\n",
        "f1_score_RF = metrics.f1_score(y_test, Model2_prediction)\n",
        "print(\"ROCAUC_RF: \", roc_auc_RF)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As the second model let's run the Random Forest model:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROCAUC_RF:  0.7896709704289878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhQAgpRzfPX0"
      },
      "source": [
        "###Question 1.3 (2 points):\n",
        "Compare those two models based on precision, recall, F1 score, accuracy, and ROCAUC metrics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8fRjfU0gFbS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "dd279691-7b51-4cf5-a6e4-d852ae1be190"
      },
      "source": [
        "print(\"Now let' s compare those two models based on precision, recall, F1 score, accuracy, and ROCAUC metrics:\")\n",
        "results_df = pd.DataFrame(columns= [\"Model\", \"Precision\", \"Recall\", \"F1_Score\", \"ROCAUC\"])\n",
        "#Logistic Regression model data\n",
        "\n",
        "results_df = results_df.append({'Model': 'Logistic Regression', 'Accuracy': accuracy_LR, 'ROCAUC': roc_auc_LR, \n",
        "                                'F1_Score': f1_score_LR, 'Precision': precision_LR, 'Recall': recall_LR}, ignore_index=True)\n",
        "#Random Forest Classifier\n",
        "results_df = results_df.append({'Model': 'Random Forest', 'Accuracy': accuracy_RF, 'ROCAUC': roc_auc_RF,\n",
        "                                'F1_Score': f1_score_RF, 'Precision': precision_RF, 'Recall': recall_RF}, ignore_index=True)\n",
        "results_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now let' s compare those two models based on precision, recall, F1 score, accuracy, and ROCAUC metrics:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1_Score</th>\n",
              "      <th>ROCAUC</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.856976</td>\n",
              "      <td>0.887755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.122449</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.789671</td>\n",
              "      <td>0.850340</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Model  Precision    Recall  F1_Score    ROCAUC  Accuracy\n",
              "0  Logistic Regression   0.807692  0.428571  0.560000  0.856976  0.887755\n",
              "1        Random Forest   0.857143  0.122449  0.214286  0.789671  0.850340"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqbFLv_v7uHE"
      },
      "source": [
        "## Question 2 (1 point)\n",
        "\n",
        "One of the most known problems in classification tasks is imbalance of labels in data. \n",
        "1.  Read the [Dealing with Imbalanced Data](https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18) article and summarize the available methods to tackle the Imbalanced Classes. (0.8p) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWHh7kSoZngR"
      },
      "source": [
        "\n",
        "The article summarizes 5 different methods for dealing with imbalanced datasets:\n",
        "\n",
        "1. Change the performance metric\n",
        "2. Change the algorithm\n",
        "3. Oversample minority class\n",
        "4. Undersample majority class\n",
        "5. Generate synthetic samples\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5j1-WopCgfHD"
      },
      "source": [
        "2. Check \"HR_Employee_Attrition.csv\" dataset. Based on the label (Attrition column), you think the dataset is balanced? (0.2p) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7grkmvPPo_lP",
        "outputId": "fb4a942b-c75e-45d4-cec8-7ac523422925"
      },
      "source": [
        "print(\"Checking the dataset balance:\")\n",
        "print(\"The dataset is clearly imbalanced as it has around 84% of 0-values and 16% of 1-values.\")\n",
        "\n",
        "df_dummies[\"Attrition\"].value_counts()\n",
        "# in %\n",
        "df_dummies[\"Attrition\"].value_counts(1)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking the dataset balance:\n",
            "The dataset is clearly imbalanced as it has around 84% of 0-values and 16% of 1-values.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    0.838776\n",
              "1.0    0.161224\n",
              "Name: Attrition, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJRELwbogggp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8dR8saCgn4s"
      },
      "source": [
        "## Question 3 (2 points)\n",
        "\n",
        "This task requires a bit more than what was covered during the lab session. The only new thing here is modification of the training set, and the code example is present below. All the rest steps are the same as for models training/evaluation done during the lab session and Q1 above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50TdPT6hNyIE"
      },
      "source": [
        "### Question 3.1 (0.5 point)\n",
        "Undersample the majority class in \"HR_Employee_Attrition.csv\" dataset so that the data becomes balanced. Take X_train, y_train, X_test, y_test used in Q1. You have to undersample ONLY ***X_train*** and ***y_train***, keep *X_test* and *y_test* unchanged. You can use the code from the [Dealing with Imbalanced Data](https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18) article or the following code using [imblearn package](https://pypi.org/project/imblearn/):\n",
        "\n",
        "`from imblearn.under_sampling import RandomUnderSampler`\n",
        "\n",
        "`undersampler = RandomUnderSampler(random_state=0)`\n",
        "\n",
        "`X_train_undersampled, y_train_undersampled = undersampler.fit_resample(X_train, y_train)`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVikhQa_jVKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16ca7b0c-5b9f-4675-a73f-ac188b50ef74"
      },
      "source": [
        "print(\"Undersampling the majority class in the dataset so the data becomes balanced\")\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "undersampler = RandomUnderSampler(random_state=0)\n",
        "X_train_undersampled, y_train_undersampled = undersampler.fit_resample(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Undersampling the majority class in the dataset so the data becomes balanced\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmV9thDAgrQj"
      },
      "source": [
        "\n",
        "\n",
        "### Question 3.2 (1.5 point)\n",
        "Use the same two classification algorithms that you have chosen in the Q1 on your new undersampled train set. Compare the performance of models trained on undersampled data with models from Q1 (trained on non-undersampled data). By comparing results we mean compare precision, recall, F1 score, accuracy, and ROCAUC. \n",
        "\n",
        "So, if for Q1 you've chosen Logistic Regression (LR) and SVM, then train LR and SVM on undersampled data. Then compare LR trained on undersampled with LR trained on non-undersampled data and SVM trained on undersampled with SVM trained on non-undersampled data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGU6OuxYjV1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41643b69-733e-4903-d386-3fe977d9da40"
      },
      "source": [
        "print(\"Let's undersample the logistic regression model:\")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "model = LogisticRegression()\n",
        "result = model.fit(X_train_undersampled, y_train_undersampled)\n",
        "\n",
        "Model1_prediction2 = model.predict(X_test)\n",
        "accuracy_LR2 = model.score(X_test, y_test)\n",
        "\n",
        "probs = model.predict_proba(X_test)\n",
        "class_1_probs = probs[:,1]\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, Model1_prediction2)\n",
        "roc_auc_LR2 = metrics.auc(fpr, tpr)\n",
        "#metrics\n",
        "precision_LR2 = metrics.precision_score(y_test, Model1_prediction2)\n",
        "recall_LR2 = metrics.recall_score(y_test, Model1_prediction2)\n",
        "f1_score_LR2 = metrics.f1_score(y_test, Model1_prediction2)\n",
        "\n",
        "results_df = results_df.append({'Model': 'Logistic regression UNDERSAMPLED', 'Accuracy': accuracy_LR2, 'Precision': precision_LR2, 'Recall': recall_LR2, 'F1_Score': f1_score_LR2,\n",
        "                                'ROCAUC': roc_auc_LR2}, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's undersample the logistic regression model:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLDPVfagbfbp",
        "outputId": "5a1354df-e887-401d-ca3d-4b61fddf67fd"
      },
      "source": [
        "print(\"Let's undersample the Random Forest model:\")\n",
        "Model2_prediction2 = model_rf.predict(X_test)\n",
        "accuracy_RF2 = metrics.accuracy_score(y_test, Model2_prediction2)\n",
        "\n",
        "probs = model_rf.predict_proba(X_test)\n",
        "class_1_probs = probs[:,1]\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, class_1_probs)\n",
        "roc_auc_RF2 = metrics.auc(fpr, tpr)\n",
        "#metrics\n",
        "precision_RF2 = metrics.precision_score(y_test, Model2_prediction2)\n",
        "recall_RF2 = metrics.recall_score(y_test, Model2_prediction2)\n",
        "f1_score_RF2 = metrics.f1_score(y_test, Model2_prediction2)\n",
        "\n",
        "results_df = results_df.append({'Model': 'Random Forest UNDERSAMPLED ', 'Accuracy': accuracy_RF2,'Precision': precision_RF2, 'Recall': recall_RF2, 'F1_Score': f1_score_RF2,\n",
        "                                'ROCAUC': roc_auc_RF2}, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's undersample the Random Forest model:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "xUewDVyTeSEM",
        "outputId": "98e2a03f-12ca-4d1d-90fa-f3e39fa7f18b"
      },
      "source": [
        "print(\"Let's see the added valuesafter undersampling:\")\n",
        "results_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's see the added valuesafter undersampling:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1_Score</th>\n",
              "      <th>ROCAUC</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.807692</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.560000</td>\n",
              "      <td>0.856976</td>\n",
              "      <td>0.887755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random Forest</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.122449</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.789671</td>\n",
              "      <td>0.850340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Logistic regression UNDERSAMPLED</td>\n",
              "      <td>0.387097</td>\n",
              "      <td>0.734694</td>\n",
              "      <td>0.507042</td>\n",
              "      <td>0.751020</td>\n",
              "      <td>0.761905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Random Forest UNDERSAMPLED</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.122449</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.789671</td>\n",
              "      <td>0.850340</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              Model  Precision  ...    ROCAUC  Accuracy\n",
              "0               Logistic Regression   0.807692  ...  0.856976  0.887755\n",
              "1                     Random Forest   0.857143  ...  0.789671  0.850340\n",
              "2  Logistic regression UNDERSAMPLED   0.387097  ...  0.751020  0.761905\n",
              "3       Random Forest UNDERSAMPLED    0.857143  ...  0.789671  0.850340\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "743sNZr0ChfJ"
      },
      "source": [
        "## Question 4 (2 points)\n",
        "\n",
        "### Question 4.1 (0.5 point) \n",
        "Oversample the minority class in \"HR_Employee_Attrition.csv\" dataset so that the data becomes balanced. Take X_train, y_train, X_test, y_test used in Q1. You have to oversample **ONLY** ***X_train*** and ***y_train***, keep *X_test* and *y_test* unchanged. You can use the code from the [Dealing with Imbalanced Data](https://towardsdatascience.com/methods-for-dealing-with-imbalanced-data-5b761be45a18) article or the following code using [imblearn package](https://pypi.org/project/imblearn/):\n",
        "\n",
        "`from imblearn.over_sampling import RandomOverSampler`\n",
        "\n",
        "`oversampler = RandomOverSampler(random_state=0)`\n",
        "\n",
        "`X_train_oversampled, y_train_oversampled = oversampler.fit_resample(X_train, y_train)`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAQa74r9hQTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55255ca2-4d91-4d87-9e15-21eeb4edad8f"
      },
      "source": [
        "print(\"Oversampling the majority class in the dataset so the data becomes balanced\")\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "oversampler = RandomOverSampler(random_state=0)\n",
        "X_train_oversampled, y_train_oversampled = oversampler.fit_resample(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oversampling the majority class in the dataset so the data becomes balanced\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AverPH4ehOQz"
      },
      "source": [
        "\n",
        "### Question 4.2 (1.5 point)\n",
        " Use the same two classification algorithms that you have chosen in the Q1 on your new oversampled train set. Compare the performance of models trained on oversampled data with models from Q1 (trained on non-oversampled data). By comparing results we mean compare precision, recall, F1 score, accuracy, and ROCAUC. \n",
        "\n",
        "So, if for Q1 you've chosen Logistic Regression (LR) and SVM, then train LR and SVM on oversampled data. Then compare LR trained on oversampled with LR trained on non-oversampled data and SVM trained on oversampled with SVM trained on non-oversampled data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkW7_kl4hP5S"
      },
      "source": [
        "print(\"Let's oversample the logistic regression model:\")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "model = LogisticRegression()\n",
        "result = model.fit(X_train_oversampled, y_train_oversampled)\n",
        "\n",
        "Model1_prediction3 = model.predict(X_test)\n",
        "accuracy_LR3 = model.score(X_test, y_test)\n",
        "\n",
        "probs = model.predict_proba(X_test)\n",
        "class_1_probs = probs[:,1]\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, Model1_prediction3)\n",
        "roc_auc_LR3 = metrics.auc(fpr, tpr)\n",
        "#metrics\n",
        "precision_LR3 = metrics.precision_score(y_test, Model1_prediction3)\n",
        "recall_LR3 = metrics.recall_score(y_test, Model1_prediction3)\n",
        "f1_score_LR3 = metrics.f1_score(y_test, Model1_prediction3)\n",
        "\n",
        "results_df = results_df.append({'Model': 'Logistic regression OVERSAMPLED', 'Accuracy': accuracy_LR3, 'Precision': precision_LR3, 'Recall': recall_LR3, 'F1_Score': f1_score_LR3,\n",
        "                                'ROCAUC': roc_auc_LR3}, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtFT4MF3fYrb",
        "outputId": "ef702022-d8a4-4a6a-fc11-8c1b783987fd"
      },
      "source": [
        "print(\"Let's oversample the Random Forest model:\")\n",
        "model_rf = RandomForestClassifier(n_estimators=1000 , oob_score = True, n_jobs = -1,\n",
        "                                  random_state =50, max_features = \"auto\",\n",
        "                                  max_leaf_nodes = 30)\n",
        "\n",
        "model_rf.fit(X_train_oversampled, y_train_oversampled)\n",
        "\n",
        "#Predictions\n",
        "Model2_prediction3 = model_rf.predict(X_test)\n",
        "accuracy_RF3 = metrics.accuracy_score(y_test, Model2_prediction3)\n",
        "\n",
        "\n",
        "probs = model_rf.predict_proba(X_test)\n",
        "class_1_probs = probs[:,1]\n",
        "fpr, tpr, thresholds = metrics.roc_curve(y_test, class_1_probs)\n",
        "roc_auc_RF3 = metrics.auc(fpr, tpr)\n",
        "#metrics\n",
        "precision_RF3 = metrics.precision_score(y_test, Model2_prediction3)\n",
        "recall_RF3 = metrics.recall_score(y_test, Model2_prediction3)\n",
        "f1_score_RF3 = metrics.f1_score(y_test, Model2_prediction3)\n",
        "results_df = results_df.append({'Model': 'Random Forest OVERSAMPLED ', 'Accuracy': accuracy_RF3,'Precision': precision_RF3, 'Recall': recall_RF3, 'F1_Score': f1_score_RF3,\n",
        "                                'ROCAUC': roc_auc_RF3}, ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's oversample the Random Forest model:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzQdqfZDhZYF"
      },
      "source": [
        "print(\"Now let's see the whole picture:\")\n",
        "\n",
        "results_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc0BZVzs0ftg"
      },
      "source": [
        "# How complicate the homework was (from 0 to 10)?|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_PvfK5Xj6hA"
      },
      "source": [
        "The homework was not too complicated after watching the lab sessions, the videos were very helpful."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COkdaj3U0jIx"
      },
      "source": [
        "# How many hours you spent for this homework?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ky07IVJkapX"
      },
      "source": [
        "With time for the lab videos about 8 hours."
      ]
    }
  ]
}